{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction to Inferential Statistics**"
      ],
      "metadata": {
        "id": "ELWlnc3JDlIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 What is inferential statistics**\n",
        "\n",
        "Inferential statistics is a branch of statistics that involves drawing conclusions or making predictions about a population based on a sample of data. It enables researchers and analysts to make inferences or generalizations about a larger group, known as the population, by using data collected from a smaller subset of that population, known as the sample.\n"
      ],
      "metadata": {
        "id": "20Cc6kuiDsWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Why use inferential statistics?**\n",
        "\n",
        "Inferential statistics is used for several important reasons in data analysis and research:\n",
        "\n",
        "1. **Generalization**: Inferential statistics allows us to make generalizations about a larger population based on a smaller sample. Instead of studying the entire population, which can be impractical or impossible in many cases, we can draw meaningful conclusions by analyzing a representative sample.\n",
        "\n",
        "2. **Hypothesis Testing**: It enables researchers to test hypotheses and determine whether there are significant differences or relationships between variables. By conducting hypothesis tests, we can make informed decisions about the population based on the sample data.\n",
        "\n",
        "3. **Prediction**: Inferential statistics allows us to make predictions about future outcomes or behaviors based on the relationships observed in the sample data. This is particularly useful in forecasting, marketing, and various other fields.\n",
        "\n",
        "4. **Decision Making**: It provides a framework for decision-making under uncertainty. By using confidence intervals, we can estimate the range within which population parameters are likely to fall, assisting in making well-informed choices.\n",
        "\n",
        "5. **Scientific Inference**: In scientific research, inferential statistics is crucial for drawing meaningful conclusions from experiments or observational studies. It helps researchers assess the significance of their findings and determine whether the observed effects are likely to be due to chance or represent true relationships.\n",
        "\n",
        "6. **Efficiency**: Using inferential statistics saves time, resources, and effort since it allows us to work with smaller samples rather than the entire population. This efficiency is particularly valuable when dealing with large or diverse populations.\n",
        "\n",
        "7. **Validity and Reliability**: Inferential statistics aids in assessing the validity and reliability of research findings. By employing appropriate statistical techniques, researchers can ensure the accuracy and robustness of their conclusions.\n",
        "\n",
        "8. **Policy and Decision Impact**: In various fields like public health, economics, and social sciences, inferential statistics plays a critical role in influencing policies and making informed decisions. The results obtained from data analysis can guide governments, organizations, and businesses in formulating effective strategies and interventions.\n",
        "\n",
        "Overall, inferential statistics is an essential tool for extracting meaningful insights and knowledge from data, enabling us to make informed decisions, draw reliable conclusions, and understand the underlying patterns and relationships within a population."
      ],
      "metadata": {
        "id": "e9-5seuGE0mS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3 Types of inferential statistics**\n",
        "\n",
        "Inferential statistics encompasses several techniques and methods used to draw conclusions and make predictions about populations based on sample data. Some of the most common types of inferential statistics include:\n",
        "\n",
        "1. **Hypothesis Testing:** Hypothesis testing is a fundamental inferential statistical method used to test the validity of a claim or hypothesis about a population parameter. Researchers set up null and alternative hypotheses and use sample data to determine if there is enough evidence to reject the null hypothesis in favor of the alternative hypothesis.\n",
        "\n",
        "2. **Confidence Intervals:** Confidence intervals provide a range of values within which a population parameter is likely to fall with a certain level of confidence. For example, a 95% confidence interval for a population mean would suggest that we are 95% confident that the true population mean lies within that interval.\n",
        "\n",
        "3. **Correlation Analysis:** Correlation analysis is used to measure the strength and direction of the relationship between two continuous variables. It helps identify if variables are positively or negatively related.\n",
        "\n",
        "3. **Regression Analysis:** Regression analysis is used to establish relationships between variables and predict outcomes. It helps in understanding how one or more independent variables influence a dependent variable and allows for making predictions based on the relationships observed in the sample.\n",
        "\n",
        "4. **Analysis of Variance (ANOVA):** ANOVA is a statistical technique used to compare means among multiple groups. It determines if there are any statistically significant differences between the means of three or more groups.\n",
        "\n",
        "5. **Chi-Square Test:** The chi-square test is used to determine if there is a significant association between two categorical variables. It assesses whether the observed frequencies differ significantly from the expected frequencies.\n",
        "\n",
        "\n",
        "These are just a few examples of the types of inferential statistics used in data analysis and research. The choice of the appropriate method depends on the research question, the type of data, and the specific assumptions of the statistical test.\n"
      ],
      "metadata": {
        "id": "MMTUww9mFTHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Hypothesis Testing**\n",
        "\n",
        "\n",
        "Hypothesis testing is a statistical method used to make inferences about population parameters based on sample data. It involves formulating two competing hypotheses and testing them to determine if there is enough evidence to support one hypothesis over the other. The two hypotheses are known as the null hypothesis (H0) and the alternative hypothesis (H1 or Ha).\n",
        "\n",
        "1. **Null Hypothesis (H0)**: The null hypothesis is the default assumption or the status quo. It states that there is no significant difference or effect, and any observed differences are due to chance or random variation. It is denoted as H0.\n",
        "\n",
        "2. **Alternative Hypothesis (H1 or Ha)**: The alternative hypothesis is the opposite of the null hypothesis. It represents the claim or effect that the researcher wants to test and find evidence for. It suggests that there is a significant difference or effect in the population. It is denoted as H1 or Ha.\n",
        "\n",
        "The goal of hypothesis testing is to assess whether the sample data provides enough evidence to reject the null hypothesis in favor of the alternative hypothesis. This is typically done by calculating a test statistic and comparing it to a critical value or using a p-value."
      ],
      "metadata": {
        "id": "5wKMVlRKGegy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Steps in hypothesis testing**\n",
        "\n",
        "The general steps of hypothesis testing are as follows:\n",
        "\n",
        "1. **Formulate Hypotheses**: Clearly state the null hypothesis (H0) and the alternative hypothesis (H1 or Ha) based on the research question.\n",
        "\n",
        "2. **Choose a Significance Level (α)**: The significance level (alpha) is the probability of rejecting the null hypothesis when it is actually true. It is typically set at 0.05 (5%) or 0.01 (1%), but researchers can choose other values based on the level of risk they are willing to tolerate for making a Type I error (false positive).\n",
        "\n",
        "3. **Select a Test Statistic**: The choice of the test statistic depends on the type of data and the research question. Common test statistics include t-test, z-test, chi-square test, ANOVA, etc.\n",
        "\n",
        "4. **Calculate the Test Statistic**: Use the sample data to compute the test statistic.\n",
        "\n",
        "5. **Determine the Critical Region or p-value**: Based on the significance level (α), find the critical region or calculate the p-value. The critical region is the range of values for the test statistic that leads to the rejection of the null hypothesis. The p-value is the probability of obtaining results as extreme as, or more extreme than, the observed results under the assumption that the null hypothesis is true.\n",
        "\n",
        "6. **Make a Decision**: Compare the test statistic to the critical value or compare the p-value to the significance level. If the test statistic falls within the critical region or the p-value is less than the significance level, reject the null hypothesis in favor of the alternative hypothesis. Otherwise, fail to reject the null hypothesis.\n",
        "\n",
        "7. **Draw Conclusions**: Based on the decision, interpret the results and draw conclusions about the population."
      ],
      "metadata": {
        "id": "Kl_lzCT2QiIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "marketing_df = pd.read_csv(\"/content/ifood_df.csv\")\n",
        "# Step 1: Formulate Hypotheses\n",
        "# Null Hypothesis (H0): There is no significant difference in income between customers who accepted the overall marketing campaigns and customers who did not.\n",
        "# Alternative Hypothesis (H1): There is a significant difference in income between customers who accepted the overall marketing campaigns and customers who did not.\n",
        "\n",
        "# Step 2: Choose a Significance Level (α)\n",
        "alpha = 0.05  # We choose a significance level of 0.05 (5%).\n",
        "\n",
        "# Step 3: Select a Test Statistic\n",
        "# For comparing means of two independent groups (customers who accepted and did not accept the overall marketing campaigns), we use the t-test.\n",
        "# Assuming unequal variances (equal_var=False) in the t-test.\n",
        "\n",
        "# Separate data for customers who accepted and did not accept the overall marketing campaigns\n",
        "accepted_income = marketing_df[marketing_df['AcceptedCmpOverall'] == 1]['Income']\n",
        "not_accepted_income = marketing_df[marketing_df['AcceptedCmpOverall'] == 0]['Income']\n",
        "\n",
        "# Step 4: Calculate the Test Statistic\n",
        "t_stat, p_value = ttest_ind(accepted_income, not_accepted_income, equal_var=False)\n",
        "\n",
        "# Step 5: Determine the Critical Region or p-value\n",
        "# Critical region (Reject H0) if p-value < alpha\n",
        "# P-value is the probability of getting the observed result (or more extreme) under the null hypothesis.\n",
        "# Smaller p-value indicates stronger evidence against the null hypothesis.\n",
        "print(\"Calculated t-statistic:\", t_stat)\n",
        "print(\"Calculated p-value:\", p_value)\n",
        "\n",
        "# Step 6: Make a Decision\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference in income between customers who accepted and did not accept the overall marketing campaigns.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in income between customers who accepted and did not accept the overall marketing campaigns.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uH8Mt0vqZ05",
        "outputId": "fd105fed-e9ea-4b0e-d234-d1d52895fb16"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated t-statistic: 9.40885742996679\n",
            "Calculated p-value: 2.868110200858913e-19\n",
            "Reject the null hypothesis. There is a significant difference in income between customers who accepted and did not accept the overall marketing campaigns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 Types of hypothesis tests**\n",
        "\n"
      ],
      "metadata": {
        "id": "FIX8rz3FTG-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Hypothesis tests are an essential part of statistical inference, used to make decisions based on sample data regarding population parameters. There are several types of hypothesis tests, each suited for different scenarios and types of data. Here are some common types of hypothesis tests:"
      ],
      "metadata": {
        "id": "bJPKS2QJh43X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **1. ANOVA (Analysis of Variance):**\n",
        "\n",
        "#### ANOVA is used to compare the means of three or more independent groups to determine if there are any statistically significant differences among them. It can be extended to multiple factors (e.g., two-way ANOVA) to analyze their combined effects.\n",
        "\n",
        "![ANOVA.webp](data:image/webp;base64,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)\n",
        "\n",
        "Reference : https://www.juran.com/blog/analysis-of-variance-anova/"
      ],
      "metadata": {
        "id": "Bwpfx4hXdAXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Chi-Square Test:**\n",
        "\n",
        " The chi-square test is used to examine the association between categorical variables. It assesses whether the observed frequencies differ significantly from the expected frequencies under the null hypothesis.\n",
        "![chi-square_right-tail.webp](data:image/webp;base64,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)\n",
        "\n",
        "Reference : https://statisticsbyjim.com/hypothesis-testing/chi-square-table/"
      ],
      "metadata": {
        "id": "GwGCcFwFei86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3 Statistical Significance of  Hypothesis Testing**\n",
        "\n",
        "Statistical significance is a critical concept in hypothesis testing. It helps determine whether the results observed in a sample are likely due to a real effect or simply due to random chance. In other words, statistical significance assesses the likelihood that the observed differences between groups or variables in a study are not just random fluctuations but rather reflect true differences in the underlying populations.\n",
        "\n",
        "When conducting a hypothesis test, the process typically involves the following steps:\n",
        "\n",
        "1. **Formulating the Hypotheses:** The researcher defines two hypotheses: the null hypothesis (H0) and the alternative hypothesis (Ha). The null hypothesis represents the default assumption that there is no significant difference or effect, while the alternative hypothesis suggests there is a significant difference or effect.\n",
        "\n",
        "2. **Choosing the Test Statistic:** Depending on the type of data and research question, an appropriate test statistic is selected. Common test statistics include t-tests, F-tests, chi-square tests, and more, as mentioned in the previous response.\n",
        "\n",
        "3. **Setting the Significance Level (α):** The significance level, denoted by α, is the threshold chosen to determine what level of evidence is needed to reject the null hypothesis. Commonly used values for α are 0.05 (5%) and 0.01 (1%). If the calculated p-value (probability value) is less than or equal to α, the results are deemed statistically significant.\n",
        "\n",
        "4. **Collecting and Analyzing Data:** Data is collected from the sample or samples under study, and the test statistic is calculated based on this data.\n",
        "\n",
        "5. **Calculating the p-value:** The p-value is the probability of obtaining a test statistic as extreme as, or more extreme than, the one observed in the sample, assuming the null hypothesis is true. If the p-value is smaller than α, the results are considered statistically significant, indicating that the null hypothesis should be rejected in favor of the alternative hypothesis.\n",
        "\n",
        "6. **Interpreting Results:** If the p-value is less than or equal to α, the results are considered statistically significant, and the researcher can reject the null hypothesis in favor of the alternative hypothesis. On the other hand, if the p-value is greater than α, there is insufficient evidence to reject the null hypothesis, and no statistically significant difference or effect is detected.\n",
        "\n",
        "It's essential to note that statistical significance does not guarantee practical significance or real-world importance. Even though a result may be statistically significant, it may still have limited practical implications. Additionally, hypothesis testing alone does not prove causation, as other factors could be influencing the observed results. Hence, it is crucial to interpret statistical significance in the context of the research question and study design."
      ],
      "metadata": {
        "id": "kc_eEsTaZRVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.4 Applications of Hypothesis Testing**\n",
        "\n",
        "Hypothesis testing has numerous applications in various fields to make data-driven decisions and draw meaningful conclusions. Here are some common applications of hypothesis testing:\n",
        "\n",
        "1. **Medical Research:** Hypothesis testing is widely used in medical research to evaluate the effectiveness of new treatments or drugs. Researchers use hypothesis tests to determine if a new treatment significantly outperforms a placebo or an existing treatment.\n",
        "\n",
        "2. **Quality Control and Manufacturing:** Businesses often use hypothesis testing to assess the quality of products and processes. It helps identify whether changes in manufacturing methods lead to significant improvements or if products meet certain quality standards.\n",
        "\n",
        "3. **A/B Testing in Marketing:** Hypothesis testing is frequently used in A/B testing, where two different versions of a marketing campaign or website are compared to determine which one performs better in terms of user engagement or conversions.\n",
        "\n",
        "4. **Education and Psychology:** Researchers use hypothesis testing to assess the impact of educational interventions or psychological treatments, determining if they result in statistically significant improvements.\n",
        "\n",
        "5. **Environmental Studies:** Hypothesis testing is used to investigate the effects of environmental factors, such as pollution or climate change, on ecosystems and living organisms.\n",
        "\n",
        "6. **Finance and Economics:** In finance, hypothesis testing is employed to analyze the performance of investment portfolios or to test the significance of financial market anomalies. In economics, it is used to study the impact of policy changes on economic indicators.\n",
        "\n",
        "7. **Social Sciences:** Researchers in social sciences, such as sociology and anthropology, use hypothesis testing to study various social phenomena and understand the significance of observed differences or correlations.\n",
        "\n",
        "8. **Biology and Genetics:** Hypothesis testing is employed in biological and genetic studies to determine if certain genetic traits are linked to specific diseases or if certain treatments have a significant impact on biological systems.\n",
        "\n",
        "9. **Sports Analytics:** Hypothesis testing is used in sports analytics to determine if certain strategies or player attributes significantly affect team performance.\n",
        "\n",
        "10. **Polling and Market Research:** Pollsters and market researchers use hypothesis testing to draw conclusions about public opinion, consumer behavior, and market trends based on collected data.\n",
        "\n",
        "11. **Education Policy:** Educational policymakers use hypothesis testing to evaluate the effectiveness of educational policies and interventions on student performance and outcomes.\n",
        "\n",
        "These are just a few examples, and the applications of hypothesis testing are vast and diverse. In general, hypothesis testing is a fundamental tool for making data-driven decisions and drawing reliable conclusions based on empirical evidence."
      ],
      "metadata": {
        "id": "DxhaHjh4YfRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Confidence Intervals**"
      ],
      "metadata": {
        "id": "obXse5AxZ1hf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1 What is Confidence Intervals**\n",
        "\n",
        "A confidence interval is a range of values that is used to estimate an unknown population parameter, such as the mean, proportion, or standard deviation. It provides a measure of the uncertainty associated with the estimation process. Confidence intervals are commonly used in statistics and data analysis to quantify the precision of a sample estimate and to infer information about the true population parameter."
      ],
      "metadata": {
        "id": "gnhxdUsoaCG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2 Calculating confidence intervals**\n",
        "\n",
        "Calculating confidence intervals involves using sample data, selecting an appropriate formula or method based on the type of data and sample size, and determining the level of confidence desired. Here are the general steps to calculate confidence intervals for population parameters:\n",
        "\n",
        "1. **Determine the Type of Data and Parameter of Interest:**\n",
        "Identify the type of data you have (e.g., continuous, categorical) and the population parameter you want to estimate (e.g., population mean, population proportion).\n",
        "\n",
        "2. **Collect a Representative Sample:**\n",
        "Collect a random and representative sample from the population of interest. The sample should be unbiased and reflect the characteristics of the larger population.\n",
        "\n",
        "3. **Calculate Sample Statistics:**\n",
        "Calculate the necessary sample statistics based on the type of parameter you are estimating. For example:\n",
        "   - For estimating the population mean (μ) with a known population standard deviation (σ), use the sample mean (x̄) and the formula: Confidence Interval = x̄ ± Z * (σ / √n), where Z is the critical value from the standard normal distribution corresponding to the desired level of confidence, and n is the sample size.\n",
        "  -For estimating the population mean (μ) with an unknown population standard deviation, use the sample mean (x̄), the sample standard deviation (s), and the t-distribution. The formula is similar to the one above but uses the t-distribution critical value instead of Z.\n",
        "  - For estimating the population proportion (p), use the sample proportion (p̂) and the formula: Confidence Interval = p̂ ± Z * √((p̂ * (1 - p̂)) / n), where Z is the critical value from the standard normal distribution corresponding to the desired level of confidence, and n is the sample size.\n",
        "\n",
        "4. **Determine the Level of Confidence (1 - α):**\n",
        "Choose the level of confidence you desire for the confidence interval. Common choices are 95% (α = 0.05) or 99% (α = 0.01). The level of confidence corresponds to the probability that the interval contains the true population parameter.\n",
        "\n",
        "5. **Find the Critical Value:**\n",
        "The critical value (Z or t) depends on the level of confidence and the type of distribution being used. You can find these values from standard normal distribution tables or t-distribution tables, or use software or calculators to determine them.\n",
        "\n",
        "6. **Calculate the Confidence Interval:**\n",
        "Using the appropriate formula, plug in the sample statistics and critical value to calculate the confidence interval. The confidence interval will be of the form \"estimate ± margin of error.\"\n",
        "\n",
        "7. **Interpretation:**\n",
        "Interpret the confidence interval by stating that you are, for example, 95% confident that the true population parameter falls within the calculated interval.\n",
        "\n",
        "Remember that the width of the confidence interval depends on the sample size and the level of confidence. Larger sample sizes or higher confidence levels result in narrower intervals, while smaller sample sizes or lower confidence levels lead to wider intervals.\n",
        "\n",
        "It's also essential to understand the assumptions and limitations of the method used to calculate the confidence interval and to use appropriate statistical techniques based on the data and study design."
      ],
      "metadata": {
        "id": "2vYJ6ngZaQ5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Select the data for income\n",
        "income_data = marketing_df['Income']\n",
        "\n",
        "# Step 2: Calculate the sample mean and sample standard deviation\n",
        "sample_mean = income_data.mean()\n",
        "sample_std = income_data.std()\n",
        "\n",
        "# Step 3: Calculate the sample size (number of observations)\n",
        "sample_size = len(income_data)\n",
        "\n",
        "# Step 4: Set the desired confidence level (e.g., 95%)\n",
        "confidence_level = 0.95\n",
        "\n",
        "# Step 5: Calculate the critical value (z-score for a t-distribution) based on the confidence level and sample size\n",
        "critical_value = t.ppf(confidence_level + (1 - confidence_level) / 2, df=sample_size - 1)\n",
        "\n",
        "# Step 6: Calculate the margin of error (ME)\n",
        "margin_of_error = critical_value * (sample_std / np.sqrt(sample_size))\n",
        "\n",
        "# Step 7: Calculate the confidence interval bounds\n",
        "lower_bound = sample_mean - margin_of_error\n",
        "upper_bound = sample_mean + margin_of_error\n",
        "\n",
        "# Step 8: Display the results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Sample Standard Deviation: {sample_std:.2f}\")\n",
        "print(f\"Sample Size: {sample_size}\")\n",
        "print(f\"Confidence Level: {confidence_level * 100}%\")\n",
        "print(f\"Margin of Error: {margin_of_error:.2f}\")\n",
        "print(f\"Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6hsSJC7r8Gu",
        "outputId": "fdeee8eb-329d-4016-bc4b-4706adc7d01f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Mean: 51622.09\n",
            "Sample Standard Deviation: 20713.06\n",
            "Sample Size: 2205\n",
            "Confidence Level: 95.0%\n",
            "Margin of Error: 865.02\n",
            "Confidence Interval: (50757.07, 52487.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we calculate the sample mean, sample standard deviation, and sample size for the income data. We then use the t.ppf() function from the scipy.stats library to find the critical value (z-score for a t-distribution) corresponding to the desired confidence level and sample size. Finally, we calculate the margin of error and the confidence interval bounds using the formula:\n",
        "\n",
        "Lower Bound = Sample Mean - Margin of Error\n",
        "\n",
        "Upper Bound = Sample Mean + Margin of Error\n",
        "\n",
        "The confidence interval represents the range within which we are 95% confident that the true population mean income lies."
      ],
      "metadata": {
        "id": "SeXrFoAOuFTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3 Interpreting confidence intervals**\n",
        "\n",
        "Interpreting confidence intervals involves understanding the uncertainty associated with an estimated population parameter based on a sample of data. When interpreting a confidence interval, consider the following points:\n",
        "\n",
        "1. **Definition of Confidence Interval:** A confidence interval is a range of values around the point estimate (e.g., sample mean or sample proportion) that is likely to contain the true population parameter with a certain level of confidence (e.g., 95% or 99%). It provides a measure of the precision or uncertainty of the estimation.\n",
        "\n",
        "2. **Level of Confidence:** The level of confidence (1 - α) is the probability that the confidence interval contains the true population parameter. For example, a 95% confidence interval implies that if we were to take multiple samples and construct confidence intervals using the same method, about 95% of those intervals would contain the true population parameter, and about 5% would not.\n",
        "\n",
        "3. **Interpretation Statement:** When reporting the confidence interval, use a statement such as: \"We are 95% confident that the true population parameter is between [lower bound] and [upper bound].\" This means that if we were to repeat the sampling and estimation process many times, about 95% of those intervals would capture the true population parameter.\n",
        "\n",
        "4. **Width of the Confidence Interval:** The width of the confidence interval reflects the precision of the estimation. A wider interval indicates more uncertainty or less precision, while a narrower interval suggests higher precision.\n",
        "\n",
        "5. **Practical Significance:** While statistical significance and confidence intervals provide information about the reliability of the estimate, it's essential to consider the practical significance of the results. Even if the confidence interval does not include a specific value (e.g., 0 for a difference between groups), the effect might still be too small to be practically meaningful.\n",
        "\n",
        "6. **Sample Size:** Larger sample sizes generally result in narrower confidence intervals because they provide more precise estimates of the population parameter.\n",
        "\n",
        "7. **Assumptions and Limitations:** Consider any assumptions or limitations in the estimation process. For example, if the data violates certain assumptions (e.g., normality, independence), the confidence interval might not be valid.\n",
        "\n",
        "8. **Comparing Intervals and Overlapping:** When comparing two groups or conditions, if the confidence intervals of their respective parameters overlap, it suggests that there is no statistically significant difference between them. Conversely, if the intervals do not overlap, it indicates a potential difference.\n",
        "\n",
        "Remember that confidence intervals provide information about the uncertainty in estimating the population parameter from a sample, but they do not make statements about causation or guarantee that the true value lies within the interval. Additionally, interpreting confidence intervals should be done in the context of the research question and the study design."
      ],
      "metadata": {
        "id": "HeHkLl-8bcJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Correlation and Regression**"
      ],
      "metadata": {
        "id": "Ww2wdlKdiTCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overview of Correlation and Regression:**\n",
        "\n",
        "Correlation and regression are two fundamental statistical techniques used to analyze the relationship between variables in a dataset. Both methods aim to quantify and understand how changes in one variable are associated with changes in another. These techniques play a crucial role in data analysis, research, and making predictions in various fields, including social sciences, economics, biology, and more.\n",
        "\n",
        "**Correlation:**\n",
        "\n",
        "Correlation measures the strength and direction of a linear relationship between two continuous variables. It quantifies how closely the data points cluster around a straight line on a scatter plot. The correlation coefficient, often denoted by \"r,\" ranges between -1 and +1:\n",
        "\n",
        "- A positive correlation (0 < r < +1) indicates that as one variable increases, the other variable tends to increase as well.\n",
        "- A negative correlation (-1 < r < 0) suggests that as one variable increases, the other variable tends to decrease.\n",
        "- A correlation coefficient near 0 implies a weak or no linear relationship between the variables.\n",
        "\n",
        "Correlation does not imply causation. Even if two variables are strongly correlated, it does not necessarily mean that one causes the other. Additionally, correlation is sensitive to outliers and nonlinear relationships, making it essential to interpret the results carefully.\n",
        "\n",
        "**Regression:**\n",
        "\n",
        "Regression builds upon correlation and extends it to predict the value of one variable (dependent variable) based on the value of another (independent variable). Simple linear regression involves fitting a straight line (linear equation) to the data points to model the relationship. The equation takes the form:\n",
        "\n",
        "**y = b0 + b1 * x**\n",
        "\n",
        "- \"y\" is the predicted value of the dependent variable.\n",
        "- \"x\" is the value of the independent variable.\n",
        "- \"b0\" is the intercept (the value of \"y\" when \"x\" is 0).\n",
        "- \"b1\" is the slope, representing the change in \"y\" for a one-unit change in \"x.\"\n",
        "\n",
        "The regression model estimates the coefficients (b0 and b1) that best fit the data, minimizing the differences between the predicted values and the actual data points. This line of best fit can then be used to make predictions for new data points.\n",
        "\n",
        "Multiple linear regression extends the concept to include more than one independent variable, allowing for more complex models and predictions.\n",
        "\n",
        "**Applications:**\n",
        "\n",
        "- Correlation: Correlation analysis is used to identify relationships between variables, such as examining the association between height and weight, the relationship between GDP and unemployment rate, or the correlation between studying time and exam scores.\n",
        "\n",
        "- Regression: Regression is employed for prediction and forecasting, such as predicting future sales based on advertising expenditure, estimating housing prices based on property features, or projecting population growth based on historical data.\n",
        "\n",
        "In summary, correlation quantifies the strength and direction of a linear relationship between variables, while regression builds on this information to predict one variable based on another. Both techniques provide valuable insights into data patterns, relationships, and predictions, making them indispensable tools in statistical analysis and decision-making.\n",
        "\n"
      ],
      "metadata": {
        "id": "3DxruQ-BidNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. ANOVA (Analysis of Variance):**"
      ],
      "metadata": {
        "id": "UcPN1rJ2s72s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.1 What is ANOVA:**\n",
        "\n",
        "ANOVA, short for Analysis of Variance, is a statistical technique used to compare the means of two or more groups to determine if there are statistically significant differences among them. It is a powerful tool for analyzing the variation between groups and within groups to assess whether any observed differences in the sample data are likely due to genuine effects or simply due to random chance.\n",
        "\n",
        "ANOVA can be used when the following conditions are met:\n",
        "\n",
        "1. Independence: The observations in each group should be independent of each other.\n",
        "\n",
        "2. Normally Distributed Data: The data should be approximately normally distributed within each group.\n",
        "\n",
        "3. Equal Variance: The variance of the data should be roughly the same across all groups. This assumption is called homogeneity of variance."
      ],
      "metadata": {
        "id": "lG9_KvX0tI3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.2 Types of ANOVA:**\n",
        "\n",
        "ANOVA can be classified into different types based on the number of factors or independent variables involved:\n",
        "\n",
        "1. **One-Way ANOVA:** This is the simplest form of ANOVA, used when there is one categorical independent variable (also called a factor) and one continuous dependent variable. It compares the means of two or more groups to determine if there is a significant difference among them.\n",
        "\n",
        "3. **Two-Way ANOVA:** Two-Way ANOVA involves two categorical independent variables (factors) and one continuous dependent variable. It allows for the examination of interactions between the two factors, in addition to testing their individual effects.\n",
        "\n",
        "4. **N-Way ANOVA:** Generalized form of ANOVA that accommodates multiple independent variables (factors) with different levels and interactions between them. It is used when there are more than two independent variables.\n",
        "\n",
        "The main output of ANOVA is the F-statistic, which measures the ratio of variation between group means to the variation within groups. A large F-statistic indicates that the variation between groups is significant relative to the variation within groups, suggesting that at least one of the group means is different from the others."
      ],
      "metadata": {
        "id": "xerB5o39tdL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.3 Interpreting ANOVA results**\n",
        "\n",
        "Interpreting ANOVA results involves understanding the output from the analysis and drawing meaningful conclusions about the differences between the groups being compared. Here are the key steps to interpret ANOVA results:\n",
        "\n",
        "1. **Null Hypothesis (H0) and Alternative Hypothesis (Ha):** First, restate the null hypothesis (H0) and alternative hypothesis (Ha) in the context of your study. The null hypothesis typically states that there are no significant differences between the group means, while the alternative hypothesis suggests that at least one group mean is different from the others.\n",
        "\n",
        "2. **F-Statistic and p-value:** Look at the F-statistic and the corresponding p-value. The F-statistic measures the ratio of variation between group means to the variation within groups. The p-value tells you the probability of observing such an extreme F-statistic by chance alone, assuming the null hypothesis is true. A small p-value (usually less than 0.05) indicates that the F-statistic is statistically significant and provides evidence to reject the null hypothesis.\n",
        "\n",
        "3. **Significance of the F-Test:** If the p-value is less than the chosen significance level (e.g., 0.05), you can conclude that there is a statistically significant difference between the group means. In this case, you reject the null hypothesis in favor of the alternative hypothesis.\n",
        "\n",
        "4. **Post-Hoc Tests (if applicable):** If you have more than two groups or factors, and the ANOVA is significant, consider conducting post-hoc tests (e.g., Tukey's test, Bonferroni correction) to identify which specific group means differ significantly from each other. Post-hoc tests help control for multiple comparisons and provide more detailed insights into the group differences.\n",
        "\n",
        "5. **Effect Size:** Although not directly provided by ANOVA, it is essential to consider the effect size, such as eta-squared (η²) or partial eta-squared (η²p), to understand the magnitude of the observed differences between groups. Effect size measures how much of the total variability in the dependent variable is explained by the independent variable(s). A larger effect size indicates a more substantial practical difference between the groups.\n",
        "\n",
        "6. **Practical Interpretation:** Always consider the practical significance of the results. A statistically significant difference does not necessarily imply that the difference is practically meaningful. Consider the context of your study and whether the observed differences are substantial enough to have real-world implications.\n",
        "\n",
        "7. **Assumptions and Limitations:** Assess the assumptions of ANOVA, such as normality and equal variance, to ensure the validity of the results. Additionally, be aware of the limitations of the ANOVA model and the study design.\n",
        "\n",
        "In summary, interpreting ANOVA results involves evaluating the statistical significance of the F-test, understanding the magnitude of the effect size, and considering the practical implications of the observed differences between groups. Careful interpretation ensures that the conclusions drawn from the analysis are meaningful and relevant to the research question at hand."
      ],
      "metadata": {
        "id": "iMBinXfbts_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The columns containing the education levels are named \"education_2n Cycle\", \"education_Basic\", \"education_Graduation\", \"education_Master\", and \"education_PhD\".\n",
        "The column containing the income information is named \"Income\"."
      ],
      "metadata": {
        "id": "8R07YhfJxoyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Step 1: Select the data for income and education level\n",
        "income_data = marketing_df['Income']\n",
        "education_levels = ['education_2n Cycle', 'education_Basic', 'education_Graduation', 'education_Master', 'education_PhD']\n",
        "\n",
        "# Step 2: Create separate income data for each education level\n",
        "income_by_education = [income_data[marketing_df[level] == 1] for level in education_levels]\n",
        "\n",
        "# Step 3: Perform ANOVA test\n",
        "f_stat, p_value = f_oneway(*income_by_education)\n",
        "\n",
        "# Step 4: Display the results\n",
        "print(\"ANOVA Results:\")\n",
        "print(\"F-statistic:\", f_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Step 5: Interpret the results\n",
        "if p_value < 0.05:\n",
        "    print(\"There is a significant difference in the mean income among customers with different education levels.\")\n",
        "else:\n",
        "    print(\"There is no significant difference in the mean income among customers with different education levels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSp5hpmTQgUj",
        "outputId": "2dfeed46-e774-4e4d-a26c-258c4ff49cf2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANOVA Results:\n",
            "F-statistic: 39.125338296263145\n",
            "P-value: 1.0965632726151262e-31\n",
            "There is a significant difference in the mean income among customers with different education levels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we first create separate income data for each education level group using list comprehension. Then, we use the f_oneway function from the scipy.stats library to perform the one-way ANOVA test. The ANOVA test determines whether there is a significant difference in the mean income among customers with different education levels. The p-value is compared to the significance level (e.g., 0.05) to draw a conclusion about the null hypothesis. If the p-value is less than the significance level, we reject the null hypothesis and conclude that there is a significant difference in the mean income. Otherwise, we fail to reject the null hypothesis, indicating no significant difference in the mean income among education levels."
      ],
      "metadata": {
        "id": "j2cq6cXnuvMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Chi-Square Test:**"
      ],
      "metadata": {
        "id": "QbDXc04mu19e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.1 What is Chi-Square Test:**\n",
        "\n",
        "The Chi-Square test is a statistical hypothesis test used to determine if there is a significant association or relationship between two categorical variables. It is particularly useful when both variables have nominal or ordinal data and are organized in a cross-tabulation (contingency table).\n",
        "\n",
        "The test is based on the difference between the observed and expected frequencies in the contingency table, assuming that there is no association between the variables (null hypothesis). The Chi-Square test calculates a test statistic (χ²) that measures how much the observed frequencies deviate from what would be expected under the assumption of independence."
      ],
      "metadata": {
        "id": "LlBDj_NDu6DJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.2 Types of chi-square tests:**\n",
        "\n",
        "There are several types of Chi-Square tests, each designed for different scenarios and types of categorical data. The three most common types of Chi-Square tests are:\n",
        "\n",
        "1. **Chi-Square Test of Independence (or Chi-Square Test for Association):**\n",
        "The Chi-Square test of independence is used to determine if there is a significant association between two categorical variables. It is applicable when both variables have nominal or ordinal data and are organized in a cross-tabulation (contingency table). The test assesses whether the observed frequencies in the contingency table are significantly different from what would be expected if the variables were independent.\n",
        "\n",
        "\n",
        "2. **Chi-Square Test of Goodness of Fit:**\n",
        "The Chi-Square test of goodness of fit is used to assess how well an observed frequency distribution fits an expected theoretical distribution. It is applied when we have one categorical variable with multiple categories (nominal or ordinal), and we want to determine if the observed frequencies differ significantly from the expected frequencies based on a hypothesized distribution.\n",
        "\n",
        "\n",
        "3. **Chi-Square Test for Homogeneity:**\n",
        "The Chi-Square test for homogeneity is used to compare the distribution of a categorical variable in two or more independent groups. It is applicable when we have one categorical variable with multiple categories and want to determine if the proportions of these categories are similar or significantly different across different groups.\n",
        "\n",
        "It's important to note that all types of Chi-Square tests share some common principles. They are based on comparing the observed and expected frequencies using the Chi-Square test statistic, and they all involve the formulation of null and alternative hypotheses to test for statistical significance. The choice of the appropriate Chi-Square test depends on the research question and the type of categorical data being analyzed."
      ],
      "metadata": {
        "id": "-l74n1JwvK8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.3 Interpreting chi-square test results**\n",
        "\n",
        "Interpreting Chi-Square test results involves assessing the statistical significance of the test and understanding the relationship between the variables being analyzed. Here are the key steps to interpret Chi-Square test results:\n",
        "\n",
        "1. **Null Hypothesis (H0) and Alternative Hypothesis (Ha):** Restate the null hypothesis and alternative hypothesis in the context of your study. The null hypothesis typically states that there is no significant association between the two categorical variables, while the alternative hypothesis suggests that there is a significant association.\n",
        "\n",
        "2. **Chi-Square Test Statistic (χ²) and Degrees of Freedom:** Look at the calculated Chi-Square test statistic value and the degrees of freedom. The degrees of freedom are determined based on the number of rows and columns in the contingency table. The Chi-Square test statistic measures how much the observed frequencies deviate from the expected frequencies under the assumption of independence. Larger Chi-Square values indicate greater discrepancies between the observed and expected frequencies.\n",
        "\n",
        "3. **Critical Value or p-value:** Find the critical value or p-value associated with the Chi-Square test statistic. The critical value is obtained from a Chi-Square distribution table based on the chosen level of significance (e.g., 0.05). Alternatively, the p-value represents the probability of observing the calculated Chi-Square value (or a more extreme value) assuming the null hypothesis is true. A small p-value (usually less than 0.05) indicates that the Chi-Square test is statistically significant.\n",
        "\n",
        "4. **Comparison with Significance Level:** Compare the obtained p-value with the chosen level of significance (alpha). If the p-value is less than alpha, you can reject the null hypothesis in favor of the alternative hypothesis. This means that there is a significant association between the two categorical variables.\n",
        "\n",
        "5. **Interpretation of Results:** If the Chi-Square test is statistically significant, you can conclude that there is evidence of a significant relationship between the two variables. However, a significant Chi-Square test does not indicate the strength or direction of the association; it only confirms that the variables are not independent. Further analysis and interpretation are required to understand the nature and strength of the relationship.\n",
        "\n",
        "6. **Effect Size:** Consider reporting the effect size, such as Cramer's V or Phi coefficient, which quantifies the strength of the association. Effect size measures how much of the variation in one variable can be explained by the other. Larger effect size values suggest a stronger relationship.\n",
        "\n",
        "7. **Assumptions and Limitations:** Assess the assumptions of the Chi-Square test, such as the independence of observations and the expected frequency counts. Additionally, be aware of any limitations in the study design or data collection that may affect the interpretation of the results.\n",
        "\n",
        "In summary, interpreting Chi-Square test results involves evaluating the statistical significance, understanding the strength of the association, and considering the implications of the findings for the research question. It is essential to interpret the results in the context of the study and to avoid making causal claims based solely on a significant Chi-Square test."
      ],
      "metadata": {
        "id": "ah2zV-ewwqrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The columns containing the marital status information are named \"marital_Divorced\", \"marital_Married\", \"marital_Single\", \"marital_Together\", and \"marital_Widow\".\n",
        "The column containing the information on whether a customer accepted the overall marketing campaigns is named \"AcceptedCmpOverall\" (with values 1 or 0)."
      ],
      "metadata": {
        "id": "dt1y_gcAxXmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Assuming you have already loaded the dataset into a DataFrame named marketing_df\n",
        "\n",
        "# Step 1: Select the data for marital status and overall campaign acceptance\n",
        "marital_status_cols = [\"marital_Divorced\", \"marital_Married\", \"marital_Single\", \"marital_Together\", \"marital_Widow\"]\n",
        "accepted_campaign = marketing_df['AcceptedCmpOverall']\n",
        "\n",
        "# Step 2: Create a contingency table (cross-tabulation) between marital status and campaign acceptance\n",
        "contingency_table = pd.crosstab(marketing_df[marital_status_cols].idxmax(axis=1), accepted_campaign)\n",
        "\n",
        "# Step 3: Perform the Chi-Square test\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Step 4: Display the results\n",
        "print(\"Chi-Square Test Results:\")\n",
        "print(\"Chi-Square Statistic:\", chi2_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "print(\"Degrees of Freedom:\", dof)\n",
        "print(\"Expected Frequencies:\")\n",
        "print(expected)\n",
        "\n",
        "# Step 5: Interpret the results\n",
        "if p_value < 0.05:\n",
        "    print(\"There is a significant relationship between marital status and overall campaign acceptance.\")\n",
        "else:\n",
        "    print(\"There is no significant relationship between marital status and overall campaign acceptance.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8pPkDlTukjW",
        "outputId": "cae3d433-7ec2-4002-d047-8988c4f52ca2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-Square Test Results:\n",
            "Chi-Square Statistic: 12.41700498175389\n",
            "P-value: 0.7148099198783464\n",
            "Degrees of Freedom: 16\n",
            "Expected Frequencies:\n",
            "[[1.82226757e+02 3.35873016e+01 8.44897959e+00 4.58956916e+00\n",
            "  1.14739229e+00]\n",
            " [6.76615873e+02 1.24711111e+02 3.13714286e+01 1.70412698e+01\n",
            "  4.26031746e+00]\n",
            " [3.77922449e+02 6.96571429e+01 1.75224490e+01 9.51836735e+00\n",
            "  2.37959184e+00]\n",
            " [4.50020862e+02 8.29460317e+01 2.08653061e+01 1.13342404e+01\n",
            "  2.83356009e+00]\n",
            " [6.02140590e+01 1.10984127e+01 2.79183673e+00 1.51655329e+00\n",
            "  3.79138322e-01]]\n",
            "There is no significant relationship between marital status and overall campaign acceptance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we first create a contingency table using the pd.crosstab function to show the counts of each combination of marital status and overall campaign acceptance. Then, we use the chi2_contingency function from the scipy.stats library to perform the Chi-Square test. The Chi-Square test determines whether there is a significant association between marital status and overall campaign acceptance. The p-value is compared to the significance level (e.g., 0.05) to draw a conclusion about the null hypothesis. If the p-value is less than the significance level, we reject the null hypothesis and conclude that there is a significant relationship between the two variables. Otherwise, we fail to reject the null hypothesis, indicating no significant relationship between marital status and overall campaign acceptance."
      ],
      "metadata": {
        "id": "nSyZA5K9xhRY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0Zjbe3JwnbA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}